{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73bf90a8",
   "metadata": {},
   "source": [
    "# ingest-croissant Workflow Demonstration\n",
    "\n",
    "If you run the [Ingest Croissant](https://docs.aperturedata.io/workflows/ingest_criossant) workflow, you can use this notebook to test the results by querying and validating that all the information from the croissant is available inside the ApertureDB instance used for ingestion destination.\n",
    "\n",
    "## Import some modules we will need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb7b73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from aperturedb.CommonLibrary import create_connector, execute_query\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# Also create a client to interact with the database. This would be reused throughout the notebook.\n",
    "client = create_connector(key=\"Get this key from the ApertureDB instance\")\n",
    "\n",
    "# define the URL of the dataset\n",
    "dataset_croissant_url = \"https://huggingface.co/api/datasets/suyc21/MedicalConverter/croissant\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70850c95",
   "metadata": {},
   "source": [
    "## Retrieve the entity called DatasetModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d462ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query = [\n",
    "    {\n",
    "        \"FindEntity\": {\n",
    "            \"with_class\": \"DatasetModel\",\n",
    "            \"_ref\": 1,\n",
    "            \"constraints\": {\n",
    "                \"url\": [\"==\", dataset_croissant_url]\n",
    "            },\n",
    "            \"results\": {\n",
    "                \"all_properties\": True\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "result, response, _ = execute_query(client, query)\n",
    "if result == 0:\n",
    "    print(json.dumps(response, indent=2))\n",
    "    df = pd.json_normalize(response[0][\"FindEntity\"][\"entities\"])\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e7d379",
   "metadata": {},
   "source": [
    "## Find the record sets associated with the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d2f50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = [\n",
    "    {\n",
    "        \"FindEntity\": {\n",
    "            \"with_class\": \"DatasetModel\",\n",
    "            \"_ref\": 1,\n",
    "            \"constraints\": {\n",
    "                \"url\": [\"==\", dataset_croissant_url]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"FindEntity\": {\n",
    "            \"_ref\": 2,\n",
    "            \"is_connected_to\": {\n",
    "                \"ref\": 1\n",
    "            },\n",
    "            \"with_class\": \"RecordsetModel\",\n",
    "            \"results\": {\n",
    "                \"all_properties\": True\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "]\n",
    "\n",
    "result, response, _ = execute_query(client, query)\n",
    "if result == 0:\n",
    "    print(json.dumps(response, indent=2))\n",
    "    df = pd.json_normalize(response[1][\"FindEntity\"][\"entities\"])\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809b051b",
   "metadata": {},
   "source": [
    "## List out a few records from each Recordset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403fa327",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = [\n",
    "    {\n",
    "        \"FindEntity\": {\n",
    "            \"_ref\": 1,\n",
    "            \"with_class\": \"DatasetModel\",\n",
    "            \"constraints\": {\n",
    "                \"url\": [\"==\", dataset_croissant_url]\n",
    "            },\n",
    "            \"results\": {\n",
    "                \"all_properties\": True\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"FindEntity\": {\n",
    "            \"_ref\": 2,\n",
    "            \"is_connected_to\": {\n",
    "                \"ref\": 1\n",
    "            },\n",
    "            \"with_class\": \"RecordsetModel\",\n",
    "            \"results\": {\n",
    "                \"all_properties\": True\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"FindEntity\": {\n",
    "            \"_ref\": 3,\n",
    "            \"is_connected_to\": {\n",
    "                \"ref\": 2,\n",
    "                \"direction\": \"out\"\n",
    "            },\n",
    "            \"results\": {\n",
    "                \"count\": True,\n",
    "                \"all_properties\": True,\n",
    "                \"group_by_source\": True,\n",
    "\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"FindEntity\": {\n",
    "            \"is_connected_to\": {\n",
    "                \"ref\": 3,\n",
    "                \"direction\": \"out\"\n",
    "            },\n",
    "            \"results\": {\n",
    "                \"count\": True,\n",
    "                \"all_properties\": True,\n",
    "                \"group_by_source\": True,\n",
    "\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "result, response, _ = execute_query(client, query)\n",
    "if result == 0:\n",
    "    print(json.dumps(response, indent=2))\n",
    "    for rs in response[1][\"FindEntity\"][\"entities\"]:\n",
    "        uniqueid = rs[\"_uniqueid\"]\n",
    "        print(f\"Recordset: {rs['uuid']}\")\n",
    "        df = pd.json_normalize(response[2][\"FindEntity\"][\"entities\"][uniqueid])\n",
    "        display(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694cd368",
   "metadata": {},
   "source": [
    "## Records with corresponding Images.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c6f84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aperturedb.NotebookHelpers import display as display_images\n",
    "from aperturedb.Images import Images\n",
    "query = query[:4]  # Keep the first three queries\n",
    "query.append({\n",
    "    \"FindImage\": {\n",
    "        \"blobs\": True,\n",
    "        \"is_connected_to\": {\n",
    "            \"ref\": 3,\n",
    "            \"direction\": \"out\"\n",
    "        },\n",
    "        \"results\": {\n",
    "            \"all_properties\": True,\n",
    "        },\n",
    "        \"limit\": 5\n",
    "    }\n",
    "})\n",
    "\n",
    "result, response, blobs = execute_query(client, query)\n",
    "print(response[4])\n",
    "if result == 0:\n",
    "    # wrapper = Images(client, response=response[4][\"FindImage\"][\"entities\"], blobs=blobs)\n",
    "    # wrapper.display()\n",
    "    display(len(blobs))\n",
    "    display_images(blobs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "package",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
