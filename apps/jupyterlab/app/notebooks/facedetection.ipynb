{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51e8af4f-b415-43e6-91a5-fb6c90aef964",
   "metadata": {},
   "source": [
    "# Face Detection and Image Similarity Search\n",
    "\n",
    "## Introduction\n",
    "When the [face detection workflow](https://docs.aperturedata.io/workflows/face_detection) is executed, it detects faces in images stored in ApertureDB and adds bounding boxes around them. \n",
    "If the \"Extract embeddings\" option is selected, embeddings are generated for each detected face bounding box.\n",
    "In this notebook, we’ll use the detected face bounding boxes and their embeddings to search for images containing similar faces.\n",
    "\n",
    "For comprehensive details on bounding boxes, polygons, and other region-based features in ApertureDB, please refer to [ApertureDB Image documentation](https://docs.aperturedata.io/category/image-and-related-commands). \n",
    "For details on the Image interface in the ApertureDB python SDK, please refer to the [python SDK documentation](https://docs.aperturedata.io/python_sdk/object_wrappers/Images).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d1ca39-2f53-47e3-a927-e122307fcf2e",
   "metadata": {},
   "source": [
    "## Common Setup\n",
    "First run the common setup to ensure a connection to the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47a8afc-74f5-45f0-850a-8484b3ebcdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set your aperturedb key here:\n",
    "# See https://docs.aperturedata.io/Setup/client/adb for more information\n",
    "WORKFLOW_APERTUREDB_KEY=\"<YOUR_APERTUREDB_KEY_HERE>\"\n",
    "\n",
    "from aperturedb.CommonLibrary import create_connector, execute_query\n",
    "from aperturedb.NotebookHelpers import display as display_images\n",
    "from aperturedb.Images import Images\n",
    "\n",
    "client = create_connector(key=WORKFLOW_APERTUREDB_KEY)\n",
    "\n",
    "# If you wish to explicitly use the Connector class, you can do so like this:\n",
    "#from aperturedb import Connector as Connector\n",
    "#client = Connector.Connector(host=\"<YOUR_HOST_NAME_HERE>\", user=\"<YOUR_USERNAME_HERE>\", password=\"<YOUR_PASSWORD_HERE>\")\n",
    "\n",
    "response, _ = client.query([{\"GetStatus\": {}}])\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ab911f-c66f-443b-bd11-78db71bf1d10",
   "metadata": {},
   "source": [
    "## Image Source\n",
    "To make this notebook easier, we have customized directions for different image sources\n",
    "1. [Images Loaded from Ingest Datasets Workflow](#ingested-dataset)\n",
    "2. [Images Loaded from Ingest from Buckets Workflow](#ingested-bucket)\n",
    "\n",
    "If you have not done either yet, the easiest way to see this workflow in action is with [Images Loaded from Ingest Datasets Workflow](#ingested-dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a25a19-d4f5-4347-aede-93830393f3d9",
   "metadata": {},
   "source": [
    "<a id=\"ingested-dataset\"></a>\n",
    "## Select an Image from Ingest Dataset Ingest\n",
    "\n",
    "### Setup\n",
    "Before running this portion of the notebook, make sure the following prerequisites are met:\n",
    "\n",
    "1. Ingest Dataset Workflow\n",
    "   Ensure that [Ingest Dataset Workflow](https://docs.aperturedata.dev/workflows/ingest_datasets) has run on your ApertureDB cloud instance. You can ingest either coco or faces. Our examples here will use faces.\n",
    "2. Face Detection with Embeddings  \n",
    "   Run the [face detection workflow](https://docs.aperturedata.io/workflows/face_detection) with \"Extract embeddings\" option enabled.\n",
    "   This step is essential for performing similarity searches based on facial features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8d915f-62ac-46ae-8fcf-5702c4421a9d",
   "metadata": {},
   "source": [
    "### Retrieve the unique id for an Image\n",
    "\n",
    "Each image loaded from the ingest dataset workflow will have a unique **adb_image_sha256** which can be used as an image identifier. \n",
    "Using the ApertureDB Web UI, you can view the images, their associated metadata properties and their bounding boxes.\n",
    "\n",
    "If you select **adb_image_sha256** from the properties list on the left, the value for each image will be shown when you click on the image thumbnail.\n",
    "\n",
    "Try running the code below, and then changing the **ADB_IMAGE_SHA_VALUE** to a different value from the Web UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ab5fda-2b32-4cbf-b1ba-6c86879fd7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADB_IMAGE_SHA_VALUE=\"432af5a94aadf103a4c7a6d356a4097b258c624d5f7be3fa5d19fd16563d08f5\"\n",
    "display_limit = 5\n",
    "query = [ {\n",
    "        \"FindImage\": {\n",
    "            \"_ref\": 1,\n",
    "            \"blobs\": True,\n",
    "            \"constraints\": {\n",
    "                \"adb_image_sha256\" : [\"==\", ADB_IMAGE_SHA_VALUE]\n",
    "            },\n",
    "            \"results\": {\n",
    "                \"all_properties\": True\n",
    "            }\n",
    "        }\n",
    "    }, {\n",
    "        \"FindBoundingBox\": {\n",
    "             \"is_connected_to\": {\n",
    "                \"ref\": 1\n",
    "            },\n",
    "            \"with_label\": \"face\",\n",
    "            \"labels\": True,\n",
    "            \"coordinates\": True,\n",
    "            \"uniqueids\": True\n",
    "        }\n",
    "    }\n",
    "   ]\n",
    "\n",
    "bbox_uniqueid = None\n",
    "response, blobs = client.query(query)\n",
    "print(f\"Bounding Box Data = {response[1]}\")\n",
    "if isinstance(response,list) and response[0][\"FindImage\"][\"returned\"] > 0:\n",
    "   imgs = Images(client, batch_size= display_limit, response=response[0][\"FindImage\"][\"entities\"])\n",
    "   imgs.display( show_bboxes= True)\n",
    "   bbox_uniqueid = response[1][\"FindBoundingBox\"][\"entities\"][0][\"_uniqueid\"]\n",
    "   print(f\"Unique Id for face bounding box for {ADB_IMAGE_ID_VALUE} is {bbox_uniqueid}\")\n",
    "else:\n",
    "    print(\"No Images returned\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e26743-5217-4913-947b-4965c3b89950",
   "metadata": {},
   "source": [
    "Once you have retrieved the image you are looking for, proceed to [retrieveing the Descriptor](#retrieve-descriptor)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9229b335-c9d9-44de-b96e-47adb32799bb",
   "metadata": {},
   "source": [
    "<a id=\"ingested-bucket\"></a>\n",
    "## Select an Image from a Bucket Ingest\n",
    "\n",
    "### Setup\n",
    "\n",
    "Before running this portion of the notebook, make sure the following prerequisites are met:\n",
    "\n",
    "1. Images in ApertureDB  \n",
    "   Ensure your ApertureDB cloud instance contains images. You can ingest images using supported workflows such as the \"[Ingest_from_Bucket](https://docs.aperturedata.dev/workflows/ingest_from_bucket)\" which allows importing data directly from AWS or GCP storage.\n",
    "2. Face Detection with Embeddings  \n",
    "   Run the [face detection workflow](https://docs.aperturedata.io/workflows/face_detection) with \"Extract embeddings\" option enabled.\n",
    "   This step is essential for performing similarity searches based on facial features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfcaae8-94a1-4ec6-9c5b-b6fef5126ad4",
   "metadata": {},
   "source": [
    "### Retrieve the unique id for an Image\n",
    "\n",
    "After running the ingest from bucket workflow, each image is assigned a unique **wf_sha1_hash** value, which can be used as an image identifier. This can be used to locate the bounding box which the facedetect workflow creates.\n",
    "\n",
    "Using the ApertureDB Web UI, you can view the images, their associated metadata properties and the linked bounding boxes.\n",
    "\n",
    "To locate the bounding box for a specific image:\n",
    "1. Search for the image using appropriate **constraints** based on metadata or hash values.\n",
    "2. Use the **FindBoundingBox** command with the **is_connected_to** parameter to retrieve bounding boxes associated with the target images.\n",
    "3. If multiple bounding boxes are returned, refer to the **coordinates**, **width**, and **height** to identify the bounding box of interest.\n",
    "\n",
    "After you've done that, put the **wf_sha1_hash** identifier in the **IMAGE_SHA1_ID** below. If there are multiple bounding boxes, you can pick the face of interest below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92568b58-8893-48ad-a67a-73b78ff2fddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "IMAGE_SHA1_ID=\n",
    "\n",
    "display_limit = 5\n",
    "query = [ {\n",
    "        \"FindImage\": {\n",
    "            \"_ref\": 1,\n",
    "            \"blobs\": True,\n",
    "            \"constraints\": {\n",
    "                \"wf_sha1_hash\" : [\"==\", IMAGE_SHA1_ID]\n",
    "            },\n",
    "            \"results\": {\n",
    "                \"all_properties\": True\n",
    "            }\n",
    "        }\n",
    "    }, {\n",
    "        \"FindBoundingBox\": {\n",
    "             \"is_connected_to\": {\n",
    "                \"ref\": 1\n",
    "            },\n",
    "            \"with_label\": \"face\",\n",
    "            \"labels\": True,\n",
    "            \"coordinates\": True,\n",
    "            \"uniqueids\": True\n",
    "        }\n",
    "    }\n",
    "   ]\n",
    "\n",
    "bbox_uniqueid = None\n",
    "bbox_data = None\n",
    "response, blobs = client.query(query)\n",
    "print(f\"Bounding Box Data = {response[1]}\")\n",
    "if isinstance(response,list) and response[0][\"FindImage\"][\"returned\"] > 0:\n",
    "   imgs = Images(client, batch_size= display_limit, response=response[0][\"FindImage\"][\"entities\"])\n",
    "   imgs.display( show_bboxes= True)\n",
    "   bbox_data = response[1][\"FindBoundingBox\"][\"entities\"]\n",
    "   if len(bbox_data) == 1:\n",
    "       print(\"Only one face detected. Selected as the target.\")\n",
    "       bbox_uniqueid = bbox_data[0][\"_uniqueid\"]\n",
    "       print(f\"Unique Id for face bounding box for {ADB_IMAGE_ID_VALUE} is {bbox_uniqueid}\")\n",
    "   else:\n",
    "       print(\"Multiple faces detected. Faces follow:\")\n",
    "       for num,face in enumerate(bbox_data):\n",
    "           print(f\"Face #{num}: {face}\")\n",
    "       print(\"Please select the target face below\")\n",
    "   \n",
    "   \n",
    "else:\n",
    "    print(\"No Images returned\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0692b8b5-cc1c-4cdf-ab5f-87775952cf69",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "If multiple faces were detected above, run the below code after putting the number listed about in `TARGET_FACE_NUMBER`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416a6fe8-988b-4d20-b8fd-19a3f5f6963c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_FACE_NUMBER=10000\n",
    "\n",
    "if bbox_uniqueid is None:\n",
    "    if bbox_data is None:\n",
    "        print(\"No Bounding Box data, please run the code above and ensure an image is returned.\")\n",
    "    elif TARGET_FACE_NUMBER == 10000:\n",
    "        print(\"Please ensure to set TARGET_FACE_NUMBER to a valid face number\")\n",
    "    else:\n",
    "        bbox_uniqueid = bbox_data[TARGET_FACE_NUMBER][\"_uniqueid\"]\n",
    "else:\n",
    "    print(\"Bounding box target is already found, skipping assignment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233036ea-bd73-491b-a0a6-33c8270d77ec",
   "metadata": {},
   "source": [
    "<a id=\"retrieve-descriptor\"></a>\n",
    "\n",
    "## Retrieving the Descriptor(Embedding) for the Target Face Bounding Box\n",
    "\n",
    "Now that you have identifed the **_uniqueid** of the bounding box corresponding to the target face, you will use the **FindDescriptor** command with the **is_connected_to** parameter to retrieve its associated descriptor(embedding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046b89a2-a1bf-4c7b-8163-b65aae255759",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = [ {\n",
    "        \"FindBoundingBox\": {\n",
    "            \"_ref\": 1,\n",
    "            \"constraints\": {\n",
    "                \"_uniqueid\" : [\"==\", bbox_uniqueid ]\n",
    "            }\n",
    "        }\n",
    "    }, {\n",
    "        \"FindDescriptor\": {\n",
    "             \"is_connected_to\": {\n",
    "                \"ref\": 1\n",
    "            },\n",
    "            \"blobs\": True,\n",
    "            \"results\": {\n",
    "                \"all_properties\": True\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "   ]\n",
    "\n",
    "response, face_blobs = client.query(query)\n",
    "if client.last_query_ok() and response[1][\"FindDescriptor\"][\"returned\"] > 0 :\n",
    "    print(f\"Descriptor found for bounding box {bbox_uniqueid}\")\n",
    "    print(response[1])\n",
    "else:\n",
    "    print(f\"No Descriptor found for bounding box {bbox_uniqueid}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bf6790-f4f3-41ff-8c2b-0d3886a5be72",
   "metadata": {},
   "source": [
    "## Find images containing a person with a similar face.\n",
    "Once we’ve identified the descriptor corresponding to the face we want to search for, we’ll use it to perform a similarity search and find photos containing similar faces.\n",
    "The descriptors generated through the face detection workflow are stored in the **wf_facenet_processed** DescriptorSet.\n",
    "Using the **FindDescriptor** command, we’ll search for the 5 nearest neighbors of the given descriptor within the wf_facenet_processed DescriptorSet. We’ll then retrieve and display the bounding boxes and images associated with those descriptors.\n",
    "For more details on FindDescriptor, please refer to the [Descriptor Commands documentation](https://docs.aperturedata.dev/query_language/Reference/descriptor_commands/desc_commands/FindDescriptor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc9c6a6-417b-4cab-ab71-f77c8176e59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = [ {\n",
    "        \"FindDescriptor\": {\n",
    "            \"_ref\": 1,\n",
    "            \"set\": \"wf_facenet_processed\",\n",
    "            \"k_neighbors\": 5,\n",
    "            \"distances\": True,\n",
    "        }\n",
    "    }, {\n",
    "        \"FindBoundingBox\": {\n",
    "            \"_ref\" :2,\n",
    "            \"blobs\": True,\n",
    "             \"is_connected_to\": {\n",
    "                \"ref\": 1\n",
    "            },\n",
    "            \"results\": {\n",
    "                \"all_properties\": True\n",
    "            }\n",
    "        }\n",
    "    }, {\n",
    "        \"FindImage\": {\n",
    "            \"blobs\": True,\n",
    "            \"is_connected_to\": {\n",
    "                \"ref\": 2\n",
    "            },\n",
    "            \"results\": {\n",
    "                \"list\": [\"wf_sha1_hash\"]\n",
    "            }\n",
    "        }\n",
    "    }]\n",
    "response, blobs = client.query(query, face_blobs)\n",
    "#print(response)\n",
    "\n",
    "bbox_blobs = blobs[:5]\n",
    "img_blobs = blobs[5:]\n",
    "print(\"face bounding boxes\")\n",
    "display_images(bbox_blobs)\n",
    "\n",
    "print(\"images\")\n",
    "display_images(img_blobs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e2a3c6-431a-46cf-b05e-1fc2531d63d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for v in os.environ.keys():\n",
    "    if not v.startswith(\"DB_\"):\n",
    "        continue\n",
    "    print(f\"- {v} = {os.environ[v]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
