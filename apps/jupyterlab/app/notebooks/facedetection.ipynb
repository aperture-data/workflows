{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51e8af4f-b415-43e6-91a5-fb6c90aef964",
   "metadata": {},
   "source": [
    "# Face Detection and Image Similarity Search\n",
    "\n",
    "## Introduction\n",
    "When the [face detection workflow](https://docs.aperturedata.io/workflows/face_detection) is executed, it detects faces in images stored in ApertureDB and adds bounding boxes around them. \n",
    "If the \"Extract embeddings\" option is selected, embeddings are generated for each detected face bounding box.\n",
    "In this notebook, we’ll use the detected face bounding boxes and their embeddings to search for images containing similar faces.\n",
    "\n",
    "For comprehensive details on bounding boxes, polygons, and other region-based features in ApertureDB, please refer to [ApertureDB Image documentation](https://docs.aperturedata.io/category/image-and-related-commands). \n",
    "For details on the Image interface in the ApertureDB python SDK, please refer to the [python SDK documentation](https://docs.aperturedata.io/python_sdk/object_wrappers/Images).\n",
    "\n",
    "## Setup\n",
    "Before running this notebook, make sure the following prerequisites are met:\n",
    "\n",
    "1. Images in ApertureDB\n",
    "   Ensure your ApertureDB cloud instance contains images. You can ingest images using supported workflows such as the \"[Ingest_from_Bucket](https://docs.aperturedata.dev/workflows/ingest_from_bucket)\" which allows importing data directly from AWS or GCP storage.\n",
    "2. Face Detection with Embeddings\n",
    "   Run the [face detection workflow](https://docs.aperturedata.io/workflows/face_detection) with \"Extract embeddings\" option enabled.\n",
    "   This step is essential for performing similarity searches based on facial features.\n",
    "\n",
    "\n",
    "## Import some modules we will need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35f2a39-0093-4129-ba64-ddd4540579bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aperturedb.CommonLibrary import create_connector, execute_query\n",
    "from aperturedb.NotebookHelpers import display as display_images\n",
    "from aperturedb.Images import Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630c8186-06b7-4fc4-9f7b-8c5cdbd2125d",
   "metadata": {},
   "source": [
    "## Set up client connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e100501c-cea2-4d22-8dbb-1078997abe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will only work if you have apererturedb installed and configured.\n",
    "# The configuration is either created by setting an APERTUREDB_KEY environment variable,\n",
    "# or by creating a configuration using adb config.\n",
    "# See https://docs.aperturedata.io/Setup/client/adb for more information.\n",
    "client = create_connector()\n",
    "\n",
    "# If you wish to explicitly use the Connector class, you can do so like this:\n",
    "#from aperturedb import Connector as Connector\n",
    "#client = Connector.Connector(host=\"<YOUR_HOST_NAME_HERE>\", user=\"<YOUR_USERNAME_HERE>\", password=\"<YOUR_PASSWORD_HERE>\")\n",
    "\n",
    "response, _ = client.query([{\"GetStatus\": {}}])\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfcaae8-94a1-4ec6-9c5b-b6fef5126ad4",
   "metadata": {},
   "source": [
    "## Retrieve the unique id of the target face boundingbox\n",
    "\n",
    "After running the face detection workflow, each image is assigned a unique **wf_sha1_hash** value, which can be used as an image identifier. \n",
    "Using the ApertureDB Web UI, you can view both the images and their associated metadata properties.\n",
    "\n",
    "To locate the bounding box for a specific image:\n",
    "1. Search for the image using appropriate **constraints** based on metadata or hash values.\n",
    "2. Use the **FindBoundingBox** command with the **is_connected_to** parameter to retrieve bounding boxes associated with the target images.\n",
    "3. If multiple bounding boxes are returned, refer to the **coordinates**, **width**, and **height** to identify the bounding box of interest.\n",
    "4. Extract the **_uniqueid** of the target bounding box for downstream tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92568b58-8893-48ad-a67a-73b78ff2fddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "display_limit = 5\n",
    "query = [ {\n",
    "        \"FindImage\": {\n",
    "            \"_ref\": 1,\n",
    "            \"blobs\": True,\n",
    "            \"constraints\": {\n",
    "                \"wf_sha1_hash\" : [\"==\", \"<YOUR_WF_SHA1_HASH>\"]\n",
    "            },\n",
    "            \"results\": {\n",
    "                \"all_properties\": True\n",
    "            }\n",
    "        }      \n",
    "    }, {\n",
    "        \"FindBoundingBox\": {            \n",
    "             \"is_connected_to\": {\n",
    "                \"ref\": 1\n",
    "            },\n",
    "            \"with_label\": \"face\",\n",
    "            \"labels\": True,\n",
    "            \"coordinates\": True,\n",
    "            \"uniqueids\": True\n",
    "        }\n",
    "    }\n",
    "   ]\n",
    "\n",
    "response, blobs = client.query(query)\n",
    "print(response[1])\n",
    "\n",
    "imgs = Images(client, batch_size= display_limit, response=response[0][\"FindImage\"][\"entities\"])\n",
    "imgs.display( show_bboxes= True)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d361497f-790d-4c21-85ed-03a73b37ae67",
   "metadata": {},
   "source": [
    "# Example response from FindBoundingBox command\n",
    "{\n",
    "    'FindBoundingBox': {\n",
    "        'entities': [\n",
    "            {\n",
    "                '_coordinates': {\n",
    "                    'height': 550, \n",
    "                    'width': 376, \n",
    "                    'x': 1954, \n",
    "                    'y': 435}, \n",
    "                '_label': 'face',\n",
    "                '_uniqueid': '1.94.7260'  # use the _uniqueid value to reference the specific bounding box in subsequent queries\n",
    "            }, \n",
    "            ...\n",
    "        ]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233036ea-bd73-491b-a0a6-33c8270d77ec",
   "metadata": {},
   "source": [
    "## Retrieving the Descriptor(Embedding) for the Target Face Bounding Box\n",
    "\n",
    "After identifying the **_uniqueid** of the bounding box corresponding to the target face, use the **FindDescriptor** command with the **is_connected_to** parameter to retrieve its associated descriptor(embedding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046b89a2-a1bf-4c7b-8163-b65aae255759",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = [ {\n",
    "        \"FindBoundingBox\": {\n",
    "            \"_ref\": 1,\n",
    "            \"constraints\": {\n",
    "                \"_uniqueid\" : [\"==\", \"1.211.12620\"]\n",
    "            }\n",
    "        }      \n",
    "    }, {\n",
    "        \"FindDescriptor\": {\n",
    "             \"is_connected_to\": {\n",
    "                \"ref\": 1\n",
    "            },\n",
    "            \"blobs\": True,\n",
    "            \"results\": {\n",
    "                \"all_properties\": True\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "   ]\n",
    "\n",
    "response, face_blobs = client.query(query)\n",
    "print(response[1])\n",
    "# print(face_blobs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bf6790-f4f3-41ff-8c2b-0d3886a5be72",
   "metadata": {},
   "source": [
    "## Find images containing a person with a similar face.\n",
    "Once we’ve identified the descriptor corresponding to the face we want to search for, we’ll use it to perform a similarity search and find photos containing similar faces.\n",
    "The descriptors generated through the face detection workflow are stored in the **wf_facenet_processed** DescriptorSet.\n",
    "Using the **FindDescriptor** command, we’ll search for the 5 nearest neighbors of the given descriptor within the wf_facenet_processed DescriptorSet. We’ll then retrieve and display the bounding boxes and images associated with those descriptors.\n",
    "For more details on FindDescriptor, please refer to the [Descriptor Commands documentation](https://docs.aperturedata.dev/query_language/Reference/descriptor_commands/desc_commands/FindDescriptor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc9c6a6-417b-4cab-ab71-f77c8176e59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = [ {\n",
    "        \"FindDescriptor\": {\n",
    "            \"_ref\": 1,\n",
    "            \"set\": \"wf_facenet_processed\",\n",
    "            \"k_neighbors\": 5,\n",
    "            \"distances\": True,\n",
    "        }      \n",
    "    }, {\n",
    "        \"FindBoundingBox\": {\n",
    "            \"_ref\" :2,\n",
    "            \"blobs\": True,\n",
    "             \"is_connected_to\": {\n",
    "                \"ref\": 1\n",
    "            },\n",
    "            \"results\": {\n",
    "                \"all_properties\": True\n",
    "            }\n",
    "        }\n",
    "    }, {\n",
    "        \"FindImage\": {\n",
    "            \"blobs\": True,\n",
    "            \"is_connected_to\": {\n",
    "                \"ref\": 2\n",
    "            },\n",
    "            \"results\": {\n",
    "                \"list\": [\"wf_sha1_hash\"]\n",
    "            }\n",
    "        }      \n",
    "    }]\n",
    "response, blobs = client.query(query, face_blobs)\n",
    "#print(response)\n",
    "\n",
    "bbox_blobs = blobs[:5]\n",
    "img_blobs = blobs[5:]\n",
    "print(\"face bounding boxes\")\n",
    "display_images(bbox_blobs)\n",
    "\n",
    "print(\"images\")\n",
    "display_images(img_blobs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
