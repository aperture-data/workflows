{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62ad0fb2-b13c-43a4-9332-3c942532d571",
   "metadata": {},
   "source": [
    "# TMDB Semantic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d81d8e0-729a-4eb3-bf1d-f0d9bbd90f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import os\n",
    "import clip\n",
    "import torch\n",
    "from aperturedb.CommonLibrary import (\n",
    "    create_connector\n",
    ")\n",
    "from aperturedb.Utils import Utils\n",
    "\n",
    "\n",
    "descriptor_set = \"ViT-B/16\"\n",
    "\n",
    "# Choose the model to be used.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "clip.available_models()\n",
    "\n",
    "# We change the descriptor set here since we are looking for images in the CLIP descriptor set\n",
    "model, preprocess = clip.load(descriptor_set, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc9590e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"APERTUREDB_KEY\"] = \"WzEsMSwicmFnLXRlc3Qtcmg4ZWNlZmwuZmFybTAwMDQuY2xvdWQuYXBlcnR1cmVkYXRhLmRldiIsInBuZmVKdnR5cXVwSDdsZ1k4RE5pOVEzZWhUV3kxYTAybXB0Il0=\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f0eb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aperturedb.Constraints import Constraints\n",
    "from aperturedb.Connector import Connector\n",
    "import json\n",
    "from aperturedb.Images import Images\n",
    "\n",
    "def find_movie_posters(db: Connector,\n",
    "    display_input:bool = True,\n",
    "    constraints: Constraints = None,\n",
    "    search_set_name: str = None,\n",
    "    embedding: bytes = None,\n",
    "    k_neighbors: int = 10,\n",
    "    output_limit:int = 10,\n",
    "    log_raw_output:bool = False) -> Images:\n",
    "    \"\"\"\n",
    "    Find similar images to the input embedding.\n",
    "    \"\"\"\n",
    "\n",
    "    #First implementation for images search.\n",
    "    find_image_command = {\n",
    "        # Retrieve the images associated with the results above.\n",
    "        \"FindImage\": {\n",
    "            # Find images connected to the descriptors returned above.\n",
    "            \"is_connected_to\": {\n",
    "                \"ref\": 1,\n",
    "            },\n",
    "            \"group_by_source\": True, # Group the results by the source descriptor.\n",
    "            \"results\": {\n",
    "                \"list\": [\"_uniqueid\"],\n",
    "                \"limit\": k_neighbors\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    if constraints is not None:\n",
    "        print(constraints.constraints)\n",
    "        find_image_command[\"FindImage\"][\"constraints\"] = constraints.constraints\n",
    "        find_image_command[\"FindImage\"][\"results\"][\"list\"].extend(list(constraints.constraints.keys()))\n",
    "\n",
    "    # This ApertureDB query finds images that are similary to the query image.\n",
    "    # Read about the [FindDescriptor](https://docs.aperturedata.io/query_language/Reference/descriptor_commands/desc_commands/FindDescriptor) command.\n",
    "    q = [{\n",
    "        # Find descriptors similar to the input descriptor.\n",
    "        \"FindDescriptor\": {\n",
    "            \"set\": search_set_name,\n",
    "            \"k_neighbors\": 100,\n",
    "            \"_ref\": 1,\n",
    "            \"distances\": True,\n",
    "            \"results\": {\n",
    "                \"all_properties\": True,\n",
    "            },\n",
    "            \"constraints\": {\n",
    "                \"source\": [\"==\", \"image\"]\n",
    "            }\n",
    "        }\n",
    "    }, find_image_command ]\n",
    "\n",
    "    # Run the query.\n",
    "    # As additional input, include the descriptor data generated from our query image above.\n",
    "    responses, images = db.query(q, [embedding])\n",
    "    # assert len(descriptors) == len(images), f\"The number of descriptors and images should be the same {responses}\"\n",
    "    print(f\"{responses=}\")\n",
    "\n",
    "    ordered_images = []\n",
    "    # Compose an ordered response of the images\n",
    "    descriptors = responses[0]['FindDescriptor']['entities']\n",
    "    images = responses[1]['FindImage']['entities']\n",
    "    for descriptor in descriptors:\n",
    "        desc_id = descriptor['_uniqueid']\n",
    "        if desc_id in images and len(images[desc_id]) > 0:\n",
    "            ordered_images.append(\n",
    "                {**images[desc_id][0]}\n",
    "            )\n",
    "            if len(ordered_images) >= output_limit:\n",
    "                break\n",
    "\n",
    "    if log_raw_output:\n",
    "        print(f\"{json.dumps(responses, indent=2)}\")\n",
    "\n",
    "    imgs = Images(db, response=ordered_images)\n",
    "    return imgs\n",
    "\n",
    "def find_movies(db: Connector,\n",
    "                display_input:bool = True,\n",
    "                movie_constraints: Constraints = None,\n",
    "                search_set_name: str = None,\n",
    "                embedding: bytes = None,\n",
    "                k_neighbors: int = 10,\n",
    "                output_limit:int = 10,\n",
    "                log_raw_output:bool = False) -> Images:\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Find similar images to the input embedding.\n",
    "    \"\"\"\n",
    "\n",
    "    find_descriptor_image_command = {\n",
    "        # Find descriptors similar to the input descriptor.\n",
    "        \"FindDescriptor\": {\n",
    "            \"set\": search_set_name,\n",
    "            \"k_neighbors\": 10000,\n",
    "            \"_ref\": 1,\n",
    "            \"results\": {\n",
    "                \"list\": [\"_uniqueid\"],\n",
    "            },\n",
    "            \"constraints\": {\n",
    "                \"source\": [\"==\", \"image\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    #First implementation for images search.\n",
    "    find_image_command = {\n",
    "        # Retrieve the images associated with the results above.\n",
    "        \"FindImage\": {\n",
    "            # Find images connected to the descriptors returned above.\n",
    "            \"is_connected_to\": {\n",
    "                \"ref\": 1,\n",
    "            },\n",
    "            \"group_by_source\": True, # Group the results by the source descriptor.\n",
    "            \"results\": {\n",
    "                \"list\": [\"_uniqueid\", \"title\"],\n",
    "                \"limit\": k_neighbors\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    find_descriptor_title_command = {\n",
    "        # Find descriptors similar to the input descriptor.\n",
    "        \"FindDescriptor\": {\n",
    "            \"set\": search_set_name,\n",
    "            \"k_neighbors\": 10000,\n",
    "            \"_ref\": 2,\n",
    "            \"results\": {\n",
    "                \"list\": [\"_uniqueid\"],\n",
    "            },\n",
    "            \"constraints\": {\n",
    "                \"source\": [\"==\", \"tagline\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    find_descriptor_tagline_command = {\n",
    "        # Find descriptors similar to the input descriptor.\n",
    "        \"FindDescriptor\": {\n",
    "            \"set\": search_set_name,\n",
    "            \"k_neighbors\": 10000,\n",
    "            \"_ref\": 3,\n",
    "            \"results\": {\n",
    "                \"list\": [\"_uniqueid\"],\n",
    "            },\n",
    "            \"constraints\": {\n",
    "                \"source\": [\"==\", \"tagline\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    #First implementation for images search.\n",
    "    find_movie_command_title = {\n",
    "        # Retrieve the images associated with the results above.\n",
    "        \"FindEntity\": {\n",
    "            \"with_class\": \"Movie\",\n",
    "            # Find images connected to the descriptors returned above.\n",
    "            \"is_connected_to\": {\n",
    "                \"ref\": 2,\n",
    "            },\n",
    "            \"group_by_source\": True, # Group the results by the source descriptor.\n",
    "            \"results\": {\n",
    "                \"list\": [\"title\", \"tagline\", \"popularity\", \"vote_average\"],\n",
    "                \"limit\": k_neighbors\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    if movie_constraints is not None:\n",
    "        print(movie_constraints.constraints)\n",
    "        find_movie_command_title[\"FindEntity\"][\"constraints\"] = movie_constraints.constraints\n",
    "\n",
    "\n",
    "    #First implementation for images search.\n",
    "    find_movie_command_tagline = {\n",
    "        # Retrieve the images associated with the results above.\n",
    "        \"FindEntity\": {\n",
    "            \"with_class\": \"Movie\",\n",
    "            # Find images connected to the descriptors returned above.\n",
    "            \"is_connected_to\": {\n",
    "                \"ref\": 3,\n",
    "            },\n",
    "            \"group_by_source\": True, # Group the results by the source descriptor.\n",
    "            \"results\": {\n",
    "                \"list\": [\"title\", \"tagline\", \"popularity\", \"vote_average\"],\n",
    "                \"limit\": k_neighbors\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    if movie_constraints is not None:\n",
    "        print(movie_constraints.constraints)\n",
    "        find_movie_command_tagline[\"FindEntity\"][\"constraints\"] = movie_constraints.constraints\n",
    "\n",
    "    # This ApertureDB query finds images that are similary to the query image.\n",
    "    # Read about the [FindDescriptor](https://docs.aperturedata.io/query_language/Reference/descriptor_commands/desc_commands/FindDescriptor) command.\n",
    "    q = [find_descriptor_image_command, find_image_command,\n",
    "         find_descriptor_title_command, find_movie_command_title,\n",
    "         find_descriptor_tagline_command, find_movie_command_tagline]\n",
    "\n",
    "\n",
    "    #print(q)\n",
    "\n",
    "    # Run the query.\n",
    "    # As additional input, include the descriptor data generated from our query image above.\n",
    "    responses, images = db.query(q, [embedding, embedding, embedding])\n",
    "    #db.print_last_response()\n",
    "\n",
    "    ordered_images = []\n",
    "    # Compose an ordered response of the images\n",
    "    descriptors = responses[0]['FindDescriptor']['entities']\n",
    "    images = responses[1]['FindImage']['entities']\n",
    "    for descriptor in descriptors:\n",
    "        desc_id = descriptor['_uniqueid']\n",
    "        if desc_id in images and len(images[desc_id]) > 0:\n",
    "            ordered_images.append(\n",
    "                {**images[desc_id][0]}\n",
    "            )\n",
    "            if len(ordered_images) >= output_limit:\n",
    "                break\n",
    "\n",
    "    print(\"##### Matches based on titles ####\\n\")\n",
    "    descriptors = responses[2]['FindDescriptor']['entities']\n",
    "    movies = responses[3]['FindEntity']['entities']\n",
    "    prop_list = []\n",
    "    for descriptor in descriptors:\n",
    "        desc_id = descriptor['_uniqueid']\n",
    "        if desc_id in movies and len(movies[desc_id]) > 0:\n",
    "            prop_list.append(movies[desc_id][0])\n",
    "    display(pd.json_normalize(prop_list))\n",
    "\n",
    "    if log_raw_output:\n",
    "        print(f\"{json.dumps(responses, indent=2)}\")\n",
    "\n",
    "    print(\"\\n##### Matches based on taglines #### \")\n",
    "    descriptors = responses[4]['FindDescriptor']['entities']\n",
    "    movies = responses[5]['FindEntity']['entities']\n",
    "    prop_list = []\n",
    "    for descriptor in descriptors:\n",
    "        desc_id = descriptor['_uniqueid']\n",
    "        if desc_id in movies and len(movies[desc_id]) > 0:\n",
    "            prop_list.append(movies[desc_id][0])\n",
    "\n",
    "    display(pd.json_normalize(prop_list))\n",
    "\n",
    "    if log_raw_output:\n",
    "        print(f\"{json.dumps(responses, indent=2)}\")\n",
    "\n",
    "    print(\"##### Matches based on images #### \")\n",
    "    imgs = Images(db, response=ordered_images)\n",
    "    return imgs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c70391-5723-48e3-8ae2-bb126687406e",
   "metadata": {},
   "outputs": [],
   "source": [
    "client=create_connector()\n",
    "utils = Utils(client)\n",
    "utils.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b2bbff-5247-494e-9084-e2da22b510e5",
   "metadata": {},
   "source": [
    "## Find movie posters by multimodal search of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeccc5e1-8e48-4e27-86b5-5f2841af8d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt for free language input\n",
    "inp = input(\"Enter a search term as described above: \")\n",
    "# action scenes in superhero movies\n",
    "# blue aliens\n",
    "\n",
    "search_tokens = clip.tokenize([f\"a photo of {inp}\"]).to(device)\n",
    "search_embeddings = model.encode_text(search_tokens)\n",
    "\n",
    "if device == \"cuda\":\n",
    "    search_embeddings = search_embeddings.float()\n",
    "    blobs = search_embeddings[0].cpu().detach().numpy().tobytes()\n",
    "else:\n",
    "    blobs = search_embeddings[0].detach().numpy().tobytes()\n",
    "\n",
    "imgs = find_movie_posters(client, embedding=blobs, k_neighbors=1000, output_limit=10, search_set_name=\"wf_embeddings_clip\")\n",
    "\n",
    "slider, table = imgs.inspect()\n",
    "display(slider, table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f391711e-7a43-41e0-909c-00043d00fbec",
   "metadata": {},
   "source": [
    "## Find movies and their posters by search in title, tagline, images (multimodal RAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a72b6f-c895-4a6d-90e3-50fdb1356c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt for free language input\n",
    "inp = input(\"Enter a search term as described above\")\n",
    "# action scenes in superhero movies\n",
    "# blue aliens\n",
    "\n",
    "search_tokens = clip.tokenize([f\"a photo of {inp}\"]).to(device)\n",
    "search_embeddings = model.encode_text(search_tokens)\n",
    "\n",
    "if device == \"cuda\":\n",
    "    search_embeddings = search_embeddings.float()\n",
    "    blobs = search_embeddings[0].cpu().detach().numpy().tobytes()\n",
    "else:\n",
    "    blobs = search_embeddings[0].detach().numpy().tobytes()\n",
    "\n",
    "imgs = find_movies(client, embedding=blobs, k_neighbors=10, output_limit=10, search_set_name=\"wf_embeddings_clip\")\n",
    "\n",
    "slider, table = imgs.inspect()\n",
    "display(slider, table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0faa5a22-8376-4744-bac9-2e318be1cdcc",
   "metadata": {},
   "source": [
    "## Vector search with additional metadata constraints (vector + graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3d9e5b-257d-4715-a21a-6cbdac34753f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aperturedb.Constraints import Constraints\n",
    "\n",
    "# Prompt for free language input\n",
    "inp = input(\"Enter a search term as described above: \")\n",
    "# action scenes in superhero movies\n",
    "# blue aliens\n",
    "\n",
    "const = Constraints()\n",
    "\n",
    "# We not only want to filter using some metadata key,value property here,\n",
    "# but want to retrieve the corresponding image in one query\n",
    "const.greater(\"popularity\", 20)\n",
    "\n",
    "search_tokens = clip.tokenize([f\"a photo of {inp}\"]).to(device)\n",
    "search_embeddings = model.encode_text(search_tokens)\n",
    "\n",
    "if device == \"cuda\":\n",
    "    search_embeddings = search_embeddings.float()\n",
    "    blobs = search_embeddings[0].cpu().detach().numpy().tobytes()\n",
    "else:\n",
    "    blobs = search_embeddings[0].detach().numpy().tobytes()\n",
    "\n",
    "imgs = helper.find_movies(client, movie_constraints=const, embedding=blobs, k_neighbors=10, output_limit=10, search_set_name=descriptor_set)\n",
    "\n",
    "slider, table = imgs.inspect()\n",
    "display(slider, table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb35a98-1f16-4363-98e3-e61d36bbed29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "package",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
