{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hello world\n",
    "\n",
    "This code validates that this jupyterlab can create a client to the Database.\n",
    "\n",
    "Please replace the values in angle brackets to the actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aperturedb.CommonLibrary import create_connector\n",
    "\n",
    "# This will only work if you have apererturedb installed and configured.\n",
    "# The configuration is either created by setting an APERTUREDB_KEY environment variable,\n",
    "# or by creating a configuration using adb config.\n",
    "# See https://docs.aperturedata.io/Setup/client/adb for more information.\n",
    "client = create_connector(key=\"Get this key from the ApertureDB instance\")\n",
    "\n",
    "# If you wish to explicitly use the Connector class, you can do so like this:\n",
    "#from aperturedb import Connector as Connector\n",
    "#client = Connector.Connector(host=\"<DB_HOST>\", user=\"admin\", password=\"<YOUR_PASSWORD_HERE>\")\n",
    "\n",
    "response, _ = client.query([{\"GetStatus\": {}}])\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other notebooks\n",
    "\n",
    "In addition, the other notebooks provided in here depend on data on your instance.\n",
    "| Notebook(s) | Data | Remarks | Related Workflow | \n",
    "| --- | --- | --- | --- |\n",
    "| boundingbox.ipynb | Images with labels of chair or person | Ingesting COCO dataset would have these images | [Dataset Ingestion (COCO)](https://docs.aperturedata.io/workflows/ingest_datasets) |\n",
    "| clip.ipynb | Images | Images present in the DB | [Generate Embeddings](https://docs.aperturedata.io/workflows/embeddings_extraction) | \n",
    "| croissant.ipynb | Any dataset represented as croissant URL | Source such datasets from kaaggle, HF, etc. | [Ingest From a croissant URL](https://docs.aperturedata.io/workflows/ingest_from_croissant) |\n",
    "| facedetection.ipynb | Images which have people in them | Ingesting COCO, celebA datasets would get some of thos images | [Dataset Ingestion](https://docs.aperturedata.io/workflows/ingest_datasets) | \n",
    "| hello.ipynb | None | This NB ensures that connectivity to a DB is up and working | |\n",
    "| mcp.ipynb | Any data | This NB has cells to interact with MCP server. | [MCP Server](https://docs.aperturedata.io/workflows/mcp_server) |\n",
    "| ocr.ipynb | Documents scanned as images | This NB lets you interact with information extracted from text extracted from images | [OCR](https://docs.aperturedata.io/workflows/ocr_extraction) |\n",
    "| rag.ipynb | A crawled website with segmentations and embeddings | | [Website Chatbot Workflow](https://docs.aperturedata.io/workflows/crawl_to_rag) |\n",
    "| sql.ipynb | Interacts with a postgres server | Can be used with sql server workflow and Aperturedb | [SQL server](https://docs.aperturedata.io/workflows/sql_server) |\n",
    "| movie_db | Notebooks to query a knowledge graph | Needs to have tmdb ingested into the Database | [Movie DB]()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "package",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
